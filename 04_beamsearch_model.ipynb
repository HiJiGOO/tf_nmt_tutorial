{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/beamsearch.ckpt\n",
      "취미가 뭐예요 <p> <p> <p>\n",
      "           ->  what is your hobby </s> </s> </s> </s> </s> </s>\n",
      "           ->  what your your hobby </s> </s> </s> </s> </s> </s>\n",
      "           ->  what is is hobby </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "만나서 반가워요 <p> <p> <p>\n",
      "           ->  nice to meet you </s> </s> </s> </s> </s> </s>\n",
      "           ->  to to meet you </s> </s> </s> </s> </s> </s>\n",
      "           ->  nice to meet </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "내일 만나서 놀아요 <p> <p>\n",
      "           ->  meet tomorrow </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "           ->  tomorrow tomorrow </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "           ->  meet tomorrow <p> <p> <p> <p> <p> <p> <p> <p>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOKEN_PAD=\"<p>\"\n",
    "TOKEN_START=\"<s>\"\n",
    "TOKEN_END=\"</s>\"\n",
    "\n",
    "ID_PAD=0\n",
    "ID_START=1\n",
    "ID_END=2\n",
    "\n",
    "source_sentences = [\"취미가 뭐예요\", \"만나서 반가워요\", \"내일 만나서 놀아요\"]\n",
    "target_sentences = [\"what is your hobby\", \"nice to meet you\", \"meet tomorrow\"]\n",
    "\n",
    "source_vocab = [TOKEN_PAD, TOKEN_START, TOKEN_END, \"취미가\", \"뭐예요\", \"만나서\", \"반가워요\", \"내일\", \"놀아요\"]\n",
    "target_vocab = [TOKEN_PAD, TOKEN_START, TOKEN_END, \"what\", \"is\", \"your\", \"hobby\", \"nice\", \"to\", \"meet\", \"you\", \"tomorrow\"]\n",
    "\n",
    "source_input_idx = [\n",
    "    [3,  4,  0,  0,  0], \n",
    "    [5,  6,  0,  0,  0],  \n",
    "    [7,  5,  8,  0,  0]]\n",
    "target_input_idx = [\n",
    "    [1,  3,  4,  5,  6], \n",
    "    [1,  7,  8,  9, 10], \n",
    "    [1,  9, 11,  0,  0]]\n",
    "target_output_idx = [\n",
    "    [3,  4,  5,  6,  2], \n",
    "    [7,  8,  9, 10,  2], \n",
    "    [9, 11,  2,  0,  0]]\n",
    "    \n",
    "source_vocab_size = len(source_vocab)\n",
    "target_vocab_size = len(target_vocab)\n",
    "\n",
    "embedding_size = 12\n",
    "num_units = 12\n",
    "\n",
    "encoder_num_layer = 3\n",
    "decoder_num_layer = 3\n",
    "\n",
    "batch_size = 3\n",
    "learning_rate = 0.0001\n",
    "\n",
    "training_steps = 40000\n",
    "display_step = 200\n",
    "\n",
    "max_sentence_length = 5\n",
    "\n",
    "beam_width = 3\n",
    "mode = \"infer\"\n",
    "\n",
    "source_inputs = tf.placeholder(dtype=tf.int64, shape=(None, max_sentence_length), name='source_inputs')\n",
    "target_inputs = tf.placeholder(dtype=tf.int64, shape=(None, max_sentence_length), name='target_inputs')\n",
    "target_outputs = tf.placeholder(dtype=tf.int64, shape=(None, max_sentence_length), name='target_outputs')\n",
    "\n",
    "sequence_lengths = [max_sentence_length] * batch_size\n",
    "\n",
    "def build_single_cell(num_units):\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "    return cell\n",
    "                   \n",
    "with tf.variable_scope('encoder'):\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    embedding_encoder = tf.get_variable(name=\"embedding_encoder\",\n",
    "                                        shape=[source_vocab_size, embedding_size], \n",
    "                                        dtype=tf.float32,\n",
    "                                        initializer=initializer,\n",
    "                                        trainable=True)\n",
    "    \n",
    "    encoder_embeddding_inputs = tf.nn.embedding_lookup(params=embedding_encoder,\n",
    "                                                       ids=source_inputs)\n",
    "    \n",
    "    # Bidirectional rnn #\n",
    "    forward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "    backward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "    bi_outputs, encoder_state = tf.nn.bidirectional_dynamic_rnn(forward_cell, \n",
    "                                                                backward_cell, \n",
    "                                                                encoder_embeddding_inputs,\n",
    "                                                                dtype=tf.float32)\n",
    "    encoder_outputs = tf.concat(bi_outputs, -1)\n",
    "    ######################\n",
    "    \n",
    "    encoder_cell_list = [build_single_cell(num_units) for i in range(encoder_num_layer-2)]\n",
    "    encoder_multi_cell = tf.contrib.rnn.MultiRNNCell(encoder_cell_list)\n",
    "    \n",
    "    encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(cell=encoder_multi_cell,\n",
    "                                                             inputs=encoder_outputs,\n",
    "                                                             dtype=tf.float32)\n",
    "\n",
    "        \n",
    "with tf.variable_scope('decoder'):\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    embedding_decoder = tf.get_variable(name=\"embedding_decoder\",\n",
    "                                        shape=[target_vocab_size, embedding_size], \n",
    "                                        dtype=tf.float32,\n",
    "                                        initializer=initializer,\n",
    "                                        trainable=True)\n",
    "    \n",
    "    decoder_embeddding_inputs = tf.nn.embedding_lookup(params=embedding_decoder,\n",
    "                                                       ids=target_inputs)\n",
    "\n",
    "    # Beam search #\n",
    "    if mode == \"train\":\n",
    "        decoder_initial_state = encoder_final_state\n",
    "        beam_batch_size = batch_size\n",
    "    if mode == \"infer\":\n",
    "        decoder_initial_state = tf.contrib.seq2seq.tile_batch(encoder_final_state, multiplier=beam_width)\n",
    "        encoder_outputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier=beam_width)\n",
    "        sequence_lengths = sequence_lengths * beam_width\n",
    "        beam_batch_size = batch_size * beam_width\n",
    "\n",
    "    ###############\n",
    "\n",
    "    decoder_cell_list = [build_single_cell(num_units) for i in range(decoder_num_layer)]\n",
    "        \n",
    "    # Attention mechanism #\n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units=num_units, \n",
    "                                                            memory=encoder_outputs,\n",
    "                                                            memory_sequence_length=sequence_lengths) \n",
    "    ######################\n",
    "    \n",
    "    # Attention mechanism #\n",
    "    for idx in range(len(decoder_cell_list)):\n",
    "        decoder_cell_list[idx] = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell=decoder_cell_list[idx],\n",
    "                attention_mechanism=attention_mechanism,\n",
    "                attention_layer_size=num_units,\n",
    "                name='Attention_Wrapper')\n",
    "    ######################\n",
    "    \n",
    "    decoder_multi_cell = tf.contrib.rnn.MultiRNNCell(decoder_cell_list)\n",
    "        \n",
    "    # Attention mechanism #\n",
    "    decoder_initial_state = decoder_multi_cell.zero_state(batch_size=beam_batch_size, dtype=tf.float32)\n",
    "    decoder_initial_state = tuple(decoder_initial_state)\n",
    "    ######################\n",
    "    \n",
    "\n",
    "\n",
    "    projection_layer = tf.layers.Dense(target_vocab_size, use_bias=False)\n",
    "    \n",
    "    # Beam search #\n",
    "    if mode == \"train\":\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(decoder_embeddding_inputs, sequence_lengths)\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(decoder_multi_cell, helper, decoder_initial_state, output_layer=projection_layer)\n",
    "        decoder_outputs, decoder_final_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder)\n",
    "\n",
    "        decoder_predict = decoder_outputs.sample_id\n",
    "        decoder_outputs = decoder_outputs.rnn_output\n",
    "        \n",
    "    if mode == \"infer\":\n",
    "        start_tokens = tf.fill([batch_size], ID_START)\n",
    "        end_token = ID_END\n",
    "        decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                                        cell=decoder_multi_cell,\n",
    "                                        embedding=embedding_decoder,\n",
    "                                        start_tokens=start_tokens,\n",
    "                                        end_token=end_token,\n",
    "                                        initial_state=decoder_initial_state,\n",
    "                                        beam_width=beam_width,\n",
    "                                        output_layer=projection_layer,\n",
    "                                        length_penalty_weight=0.0)\n",
    "        \n",
    "        decode_max_length = max_sentence_length * 2\n",
    "        decoder_outputs, decoder_final_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder,\n",
    "                                                                                   maximum_iterations = decode_max_length)\n",
    "        \n",
    "        decoder_predict = decoder_outputs.predicted_ids\n",
    "        decoder_predict = tf.transpose(decoder_predict, perm=[0, 2, 1]) #[batch_size, beam_width, time]\n",
    "        \n",
    "    ###############\n",
    "    \n",
    "    \n",
    "with tf.variable_scope(\"optimizer\"):\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=decoder_outputs,\n",
    "                                                                labels=target_outputs)\n",
    "        cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = optimizer.minimize(cost)\n",
    "\n",
    "        correct_pred = tf.equal(tf.argmax(decoder_outputs, 2), target_outputs)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    \n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Saver\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        # Run the initializer\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for step in range(1, training_steps + 1):\n",
    "            batch_source_input = source_input_idx\n",
    "            batch_target_input = target_input_idx\n",
    "            batch_target_output = target_output_idx\n",
    "\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(optimizer, feed_dict={source_inputs: batch_source_input, \n",
    "                                           target_inputs: batch_target_input,\n",
    "                                           target_outputs: batch_target_output})\n",
    "\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch accuracy & loss\n",
    "                outputs, acc, loss = sess.run([decoder_predict, accuracy, cost], feed_dict={source_inputs: batch_source_input, \n",
    "                                                                  target_inputs: batch_target_input,\n",
    "                                                                  target_outputs: batch_target_output})\n",
    "\n",
    "                print(\"Step \" + str(step * batch_size) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "\n",
    "            if acc >= 1.0:\n",
    "                for sentence in outputs:\n",
    "                    sentence = [target_vocab[word_idx] for word_idx in sentence]\n",
    "                    print(\"           -> \", sentence)\n",
    "                    \n",
    "                saver.save(sess, './save/beamsearch.ckpt')\n",
    "\n",
    "                break;\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={source_inputs: source_input_idx, \n",
    "                                                                 target_inputs: target_input_idx,\n",
    "                                                                 target_outputs: target_output_idx}))\n",
    "\n",
    "    if mode == \"infer\":\n",
    "        # Restore\n",
    "        saver.restore(sess, './save/beamsearch.ckpt')\n",
    "        \n",
    "        batch_source_input = source_input_idx\n",
    "        outputs = sess.run(decoder_predict, feed_dict={source_inputs: batch_source_input})\n",
    "        \n",
    "        for idx, output in enumerate(outputs):\n",
    "            source_sentence = [source_vocab[word_idx] for word_idx in batch_source_input[idx]]\n",
    "            print(\" \".join(source_sentence))\n",
    "            for sentence in output:\n",
    "                sentence = [target_vocab[word_idx] for word_idx in sentence]\n",
    "                print(\"           -> \", \" \".join(sentence))\n",
    "            print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
